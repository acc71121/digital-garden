---
{"dg-publish":true,"permalink":"/papers/read-diagnose-and-chat/"}
---

#LLM #OOD #COT #DSM5

Paper link: https://arxiv.org/pdf/2305.05138.pdf

9 May 2023

### Framework description

![Pasted image 20240306110215.png](/img/user/Images/Pasted%20image%2020240306110215.png)
##### Depression detection model

We represent each user sample as $(ùë•, ùë¶)$, where $x$ is a list of posts from the user‚Äôs social media account, including multiple posts $ùë•_{t1} , ùë•_{t2}, ..., ùë•_{tm}$ . Each post $ùë•_{t}$ contains both text $ùë•_{t}^{text}$ and picture  $ùë•_{t}^{pic}$ . 

$y$ - indicates whether the user has been diagnosed as a depressed individual or not. The traditional depression detection system, denoted by $F^{*}$ , utilizes the user‚Äôs social media content to determine whether the user exhibits symptoms of depression:

$\hat{y} = F^{*}(x) = F^{*} (x_{t1} , x_{t2} , ..., x_{tm})$ [1]

where $\hat{y}$ denotes the predicted diagnosis result whether the user is depressed or not. In this paper, we propose a novel but more challenging paradigm for the depression detection system. The system $F$ is required not only to provide detection results but also to provide interpretability (diagnostic evidence) and an interactive dialogue system. 

$\hat{y}, \varepsilon = F(x) = F^{*} (x_{t1} , x_{t2} , ..., x_{tm})$ [2]

where $\hat{y}$ and $\varepsilon$ denotes the diagnosis results and the generated diagnosis explanation. 
Moreover, the system is equipped with an interactive chat module that proactively engages with users. This module can be represented as: 

$R_{t} = F(c_{t}, h_{t-1}, \hat{y}, \varepsilon, x)$  [3]

where $c_{t}$ denotes the input provided by the user at round $t$ and $R_{t}$ denotes the response generated by the system at round $t$. $h_{t-1} = R_{1}, c_{2}, R_{2}, ... , R_{t-1}, c_{t-1}$ represents the dialogue history up to and including the previous $t-1$ rounds. Here, $h_{0} = None$

##### Tweet Selector $S$

The tweet selector is introduced to filter out excessive posts from the user, since LLMs cannot process too long text. The tweet selector S will select ùëõ posts as the input LLMs:

$x_{t^{'}1} , x_{t^{'}2} , ..., x_{t^{'}n} = S(x_{t1} , x_{t2} , ..., x_{tm})$ [4]

where $x_{t^{'}n} = S(x_{t1} , x_{t2} , ..., x_{tm})$ represents the collection of all $m$ posts from a particular user, while $x_{t^{'}1} , x_{t^{'}2} , ..., x_{t^{'}n}$ denotes the subset of $n$ posts that are selected. We experiment with three tweet selectors: the random selector, the recent selector and the sentiment selector. The random selector randomly selects $n$ posts, while the recent selector selects the $n$ most recent posts. The sentiment selector utilizes a sentiment analysis model to rank all ùëö posts based on their negativity scores, and then select the $n$ most negative posts. We employ GPT-3.5 as our sentiment analysis model.

###### Image Descriptor $D$

The present module employs Image Caption and Optical Character Recognition (OCR) technology to transform images into textual information, which is a crucial feature as many Language and Learning Models (LLMs) are only capable of processing text. One common approach to extract semantics from images and represent it using textual descriptions is through image captioning. The process starts with extracting the text from the image using open-source Python packages, such as EasyOCR2. Subsequently, a pre-trained image captioning model named ClipCap is applied. This model is particularly useful for generating high-quality captions for low-resolution web images. The captions produced by ClipCap typically describe the most prominent objects or events depicted in the image. The left part of Figure 2 demonstrates the effect of the Image Descriptor, which utilizes image caption and OCR to transform the visual information of an image into textual form. In the future, with LLMs capable of handling images such as GPT-4, we can directly input both images and text into the model without the need for this intermediary step.

##### Professional Diagnostic Criteria $C$ 
To facilitate the detection system‚Äôs ability to perform diagnostic procedures based on professional knowledge, rather than just classification, we have integrated the DSM depression diagnostic criteria as the Professional Diagnostic Criteria C, as depicted in Figure 3. The Diagnostic and Statistical Manual of Mental Disorders (DSM) serves as the primary reference for psychiatric diagnoses in the United States.

![Pasted image 20240306161128.png](/img/user/Images/Pasted%20image%2020240306161128.png)
##### Demonstrations $Demo$

In-context learning usually involves introducing a few ($k$) demonstrations to enable the model to learn how to accomplish the given task. Specifically, ==a demonstration refers to reformulating a labeled sample into a question-answer pair format in a text-based representation that can be understood by LLMs==. Besides, utilizing few demonstrations can effectively constrain LLMs, enabling them to output results in a fixed format

##### The Chain of Thoughts $CoT$

The Chain of Thoughts (CoT) technique involves incorporating reasoning steps into demonstrations ($Demo$) to obtain the final results. This technique enables LLMs to detect depression and provide diagnostic evidence based on the Professional Diagnostic Criteria C. The CoT demonstration comprises triples, which include input, output, and reasoning steps. The input includes the question, options, and posts, while the output indicates the final answer (diagnosis). The reasoning steps in the chain of thought reveal how to derive the answer from the question. 

==The CoT demonstration follows a specific organizational format: ==
	**Question:** Analyze someone‚Äôs tweets using DSM-5 to determine if they are depressed.
	**Options:** \[A.depressed B.non-depressed]. 
	**Posts:** \[Posts of User]. 
	**Answer:** \[A or B]. 
	**Explanation:** \[Reasoning steps].

##### Vanilla Depression Detection Model $F^{*}$ and Answer Heuristics $A$

In the full data setting, to fully exploit all available training samples, a conventional depression detection model  $F^{*}$  is introduced and trained on the entire training dataset. The resulting prediction probabilities from this model are utilized as answer heuristics $A$ and subsequently fed into the LLM as inputs. This can be expressed mathematically as:

$p(A), p(B) = F^{*}(x_{t1} , x_{t2} , ..., x_{tm})$ [5]
$A = \{p(A), p(B)\}$ [6]

where $p(A)$ and $p(B)$ are the predicted probabilities that the test user is depressed or not depressed by the conventional depression detection model, respectively, and are considered as the answer heuristics $A$. Specifically, the Time2VecTransformer is adopted as the vanilla depression detection model. However, in the few-shot and zero-shot settings, the LLM is not provided with any answer heuristics.

![Pasted image 20240306162301.png](/img/user/Images/Pasted%20image%2020240306162301.png)

##### Prompt Manager for Diagnosis $M_{ùê∑}$ : 

The prompt manager has been designed to convert all clues into a language that LLM can understand. Specifically, the prompt manager for diagnosis $M_{ùê∑}$ is responsible for constructing prompts that instruct LLMs on how to diagnose a user. We conduct the prompt with the question, the $C‚âÄT$demonstrations, the professional diagnostic criteria $C$ and the answer heuristics $A$: 
	**Question:** Analyze someone‚Äôs tweets using DSM-5 to determine if they are depressed. **Options:** \[A.depressed B.non-depressed]
	**Diagnosis criteria:** \[DSM diagnosis criteria] 
	**Demonstrations:** \[COT Demonstrations]
	**Posts:** \[Posts of User]
	**Answer candidate:** \[A P(A)]; [B P(B)]
	**Answer:** Explanation

where $COT$ Demonstrations refers to demonstrations with a chain of thoughts. And "Posts" denotes the selected list of tweets obtained from the tweet selector $S$ and image descriptor $D$, as illustrated in Figure 2. The "Answer candidate" is constructed using the answer heuristic $A$. The confidence scores for answers $A$ and $B$ are denoted by "P(A)" and "P(B)", respectively. 
These scores help to focus the attention of large language models (LLMs) on candidate answers with higher scores. We consider the answer generated by this prompt as the final diagnosis result. LLMs then fill the "Explanation" section with the diagnosis evidence. This prompt is applicable in the full data setting, where the "Answer candidate" is computed using a vanilla depression detection model trained with full training data. In the few-shot and zero-shot settings, the "Answer candidate" is not included. Moreover, the prompt used in the zero-shot setting does not contain the "Demonstrations".

##### Prompt Manager for Dialogue $M_{T}$ : 

The prompt manager for dialogue $M_{T}$ is responsible for constructing prompts that guide LLMs on how to respond to users based on their diagnosis results, explanation, social media content, and dialogue history: 
	Instruction: Chat based on user‚Äôs tweets to gather psychological information and provide advice. 
	**Posts:** \[Posts of User] 
	**Diagnosis:** \[Result],\[Explanation]
	**Dialogue history:** \[Dialogue history] 
	**Input:** \[User input]

where [Result],[Explanation] are the generated diagnosis results and evidence from our system. [User input] denotes the user‚Äôs input in the dialogue.



### Experiment setup

##### Datasets

 In this study, we evaluate our method by benchmarking it against two widely used depression datasets, namely the Twitter multimodal depression dataset ([[Datasets/TMDD\|TMDD]]) and the Weibo user depression detection dataset ([[Datasets/WU3D\|WU3D]]). Both Twitter and Weibo are popular social media platforms where users share their mental health problems. The TMDD is in English, while the WU3D is in Chinese. While both datasets include images, the textual information is more extensive in WU3D, where posts can have up to 5,000 characters compared to the 280 character limit of Twitter. For TMDD, users in the depression class were identified by detecting mentions of depression diagnosis, while users in the control group had no such indications. On the other hand, all depressed user samples in the WU3D were manually labeled by anonymous data labeling specialists and reviewed by psychologists and psychiatrists. 
 
 The TMDD contains 1,402 users diagnosed with depression and 1,402 control users. To maintain consistency with the experimental settings used in, which we could not access in the full data setting, we conducted experiments using the same settings and performed five-fold cross-validation. In the few-shot and zeroshot settings, we used 1,000 positive and 1,000 negative samples as evaluation data. Similarly, for the WU3D, we used 1000 positive and 1000 negative samples in the few-shot and zero-shot settings. Table 1 provides a summary of the dataset statistics. It is essential to note that only a small fraction of social media posts contain both text and image data.

![Pasted image 20240314104701.png](/img/user/Images/Pasted%20image%2020240314104701.png)
##### Baselines

In the full data setting, we have compared our system with several classic methods. Multimodal Topic-Enriched Auxiliary Learning (MTAL) captures the multimodal topic information through two auxiliary tasks accompanying the primary task of depression detection in visual and textual topic modeling.

Multimodal Time-Aware Attention Networks (MTAN) is a multimodal model that incorporates T-LSTM to consider the time intervals between posts. "GRU + VGG-Net + COMMA" uses a reinforcement learning component to select posts with text and images that are indicative of depression and classify them with an MLP. SetTransformer, a set-based multimodal transformer, employs zero positional encoding and random sampling of user posts, and Time2VecTransformer, a time-aware multimodal transformer, uses time-enriched positional embeddings and sub-sequence sampling. In the few shot setting, BERT(base), finetuned with 2 training samples, is compared. In the zero-shot setting, we compare our system with PTDD, which uses BERT to obtain classification results by inputting prompts.

##### Implementation Details

In our experiments, we used the public ChatGPT(gpt-3.5-turbo) and GPT-3(text-davinci-003) as the underlying language model due to its widespread usage and ease of access. For each user, we selected four posts and utilized two types of demonstrations: one positive and one negative. We
aimed to demonstrate the efficacy of our depression detection system in terms of generalization ability. To this end, we leveraged the TextAttack tool to generate out-of-distribution (OOD) test data for the TMDD. The original test data for these datasets are referred to as in-distribution (ID) test data. Specifically, we generated OOD samples by replacing original words with words that are visually similar but semantically different and by removing certain characters in words, such as "name" ‚Üí "nme."



## Results

![Pasted image 20240314105512.png](/img/user/Images/Pasted%20image%2020240314105512.png)


### References

[[Papers/!! A Time-Aware Transformer Based Model forSuicide Ideation Detection on Social Media\|!! A Time-Aware Transformer Based Model forSuicide Ideation Detection on Social Media]]


### #Useful_Features

- OOD: The original test data for these datasets are referred to as in-distribution (ID) test data. Specifically, we generated OOD samples by replacing original words with words that are visually similar but semantically different and by removing certain characters in words, such as "name" ‚Üí "nme."

- DSM-5 Criteria
- The Chain of Thoughts $CoT$
